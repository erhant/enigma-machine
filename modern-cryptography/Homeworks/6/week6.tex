\documentclass[12pt,reqno]{amsart}

\usepackage{amsthm,amsmath,amssymb}
\usepackage{mathtools}
\usepackage{proof}
\usepackage{centernot}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage[T1]{fontenc}
\usepackage{courier}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{array}
\usepackage{multirow}
\usepackage{algorithmic}
\usepackage{textcomp}
\usepackage{algorithm}
\usepackage{cite}
\usepackage{listings}
\lstset{basicstyle=\ttfamily\tiny, columns=fullflexible, language=Python, morekeywords={logical_and, log, exp, dot, sqrt, ones, identity}}
\definecolor{mySucces}{RGB}{40, 167, 69}
\definecolor{myFail}{RGB}{220, 53, 69}

\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\st}[0]{\text{ s.t. }}
\newcommand{\where}[0]{\text{ where }}
\newcommand{\mand}[0]{\text{ and }}
\newcommand{\msgspc}[0]{\mathcal{M}}
\newcommand{\cphspc}[0]{\mathcal{C}}
\newcommand{\keyspc}[0]{\mathcal{K}}
\newcommand{\advrs}[0]{\mathcal{A}}
\newcommand{\distin}[0]{\mathcal{D}}
\newcommand{\oracle}[0]{\mathcal{O}}
\newcommand{\correctans}[0]{\colorbox{mySucces}{CORRECT}}
\newcommand{\falseans}[0]{\colorbox{myFail}{FALSE}}
\newcommand\MyBox[2]{
  \fbox{\lower0.75cm
    \vbox to 1.7cm{\vfil
      \hbox to 1.7cm{\hfil\parbox{1.4cm}{#1\\#2}\hfil}
      \vfil}%
  }%
}
\graphicspath{ {./} }
\newtheorem{theorem}{Theorem}[section]
\newtheorem{axiom}[theorem]{Axiom}
\newtheorem{case}[theorem]{Case}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{conclusion}[theorem]{Conclusion}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{criterion}[theorem]{Criterion}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{solution}[theorem]{Solution}
\newtheorem{summary}[theorem]{Summary}    

\begin{document}

\begin{center}
\large\textbf{Homework 6 \\ COMP543 Fall 2020 - Modern Cryptography \\}
\normalsize\textbf{ Erhan Tezcan 0070881 \\ 11.11.2020} \\
\end{center}

\begin{center}
\line(1,0){250}
\end{center}

%
%\begin{enumerate}[label=\alph*.]
% \item Explain input, output, and the purpose of each algorithm (Key Generation, Encryption, Decryption). 
% \item What are the key space, the message space, and the ciphertext space?
% \item Formally define the   correctness   requirement of an encryption scheme.
% \end{enumerate}
%

%
%\begin{algorithm}
%\caption{\code{DivideRounds} for a new event \code{x}}
%\label{alg:round}
%\begin{algorithmic}
%\STATE $r \gets \text{max}(selfParent.Round, otherParent.Round)$
%\IF {$x \text{ strongly sees } > \frac{2n}{3} \text{ round } r \text{ witnesses}$} 
%        \STATE $x.Round \gets r+1$
%\ELSE
%        \STATE $x.Round \gets r$
%\ENDIF 
%\STATE $x.witness \gets x.Round > x.selfParent.Round$
%\end{algorithmic}
%\end{algorithm}
%
\section{Quesitons}
\textbf{Q1:} Where can/should we use hybrid proofs? How many hybrids should there be, and why?

\textbf{A1:} We use hybrid proofs when a certain primitive is applied iteratively. There are 3 rules regarding hybrids:
\begin{enumerate}
	\item There will be a first hybrid $H^{first}$ and last hybrid $H^{last}$.
	\item Given two neighbors $H^i$ and $H^{i+1}$, if we can distinguish them then the system will be broken, e.g. $H^{first}$ and $H^{last}$ will be distinguishable.
	\item There can only be polynomially many hybrids.
\end{enumerate}

\vspace{20px}
\textbf{Q2:} Define negligible, polynomial, noticeable, non-negligible, exponential functions and probabilities fully formally. Use several equivalent definitions. Try to employ Big-Oh notation as well. Moreover, answer the following:
\begin{enumerate}[label=\alph*.]
 \item $neg(k) \times poly(k) = ?$
 \item $poly(k) / exp(k) = ?$
 \item $poly(k) / superpoly(k) = ?$
 \item $noticeable(k) / poly(k) = ?$
\end{enumerate} 

\textbf{A2:} Let us include the definition of Big-O here, $f(n) = \mathcal{O}(g(n))$ means that there exist positive integers $c$ and $n'$ such that $\forall n > n'$ it holds that $f(n) \leq c\times g(n)$. $poly(k)$ is just a polynomial. 
\begin{itemize}
\item \code{poly}: $poly(k)$ is a polynomial that is in the form: $poly(k) = a_kx^k + a_{k-1}x^{k-1} + \ldots + a_1x + a_0$ where $k \in \mathbb{Z}^+$ and $\forall i \in \{0, \ldots, k\}, a_i \in \mathbb{R}$. (shown as $\mathcal{O}(x^k)$). 
 \item \code{exp}: A function $f(n)$ is an exponential function such that $f(n)=ab^n$ where $b \in \mathbb{R} \mand b>1$. $exp(n)$ is a special case of this, as $exp(n)=e^n$. 
 \item \code{negl}: $negl(k)$ is when \textbf{for all} polynomials $p$ there is an $N$ such that for all integers $n > N$ it holds that $f(n) < 1/p(n)$. Equivalently, $f(n)$ is negligible if and only if $f(n) \in \mathcal{O}(1/p(n))$ for all positive polynomials $p$. Another equivalent definition is that $f(n)$ is negligible if and only if $p(n)f(n)$ converges to 0 for all positive polynomials $p$.
  \item \code{noticable}: $noticable(k)$ is when \textbf{there exists} a polynomial $p$ and an $N$ such that for all integers $n > N$ it holds that $f(n) \geq 1/p(n)$. Equivalently, $f(n)$ is noticable if and only if $f(n) \in \mathcal{\Gamma}(1/p(n))$ for some positive polynomial $p$. Another equivalent definition is that $f(n)$ is noticable if and only if $p(n)f(n)$ goes to $\infty$ for some positive polynomial $p$. $1/p(n)$ is bounded by $ \mathcal{O}(f(n))$
 \item \code{non-negl}: Non-negligible is when if \textbf{there exists} a polynomial $p$ and \textbf{no $N$ exists} such that for all integers $n > N, f(n) < 1/p(n)$. Any function that is not negligible is non-negligible. Note that \code{noticable} and \code{non-negligible} are not necessarily the same! 
\end{itemize}
  A superpolynomial is a function that is not upperbounded by any polynomial.
\begin{enumerate}[label=\alph*.]
 \item $neg(k) \times poly(k) = neg(k)$
 \item $poly(k) / exp(k) = neg(k)$ as the reciprocal of $exp(k)$ is negligible.
 \item $poly(k) / superpoly(k) = neg(k)$ because $superpoly$ grows larger than $poly$.
 \item $noticeable(k) / poly(k) = noticeable(k)$.
\end{enumerate} 

\vspace{20px}
\textbf{Q3:} Formally define computational indistinguishability, and discuss where it can be applied. Especially, considering what you have seen until this point, where have you already applied computational indistinguishability definition (possibly without knowing it)?

\textbf{A3:} Two probability ensembles $\mathcal{X} = \{X_n\}_{n \in \mathbb{N}}$ and  $\mathcal{Y} = \{Y_n\}_{n \in \mathbb{N}}$ are \textit{computationally indistinguishable} if for every PPT distinguisher $\distin$ there exists a negligible function \code{negl} s.t.
$$
\left| \underset{x \xleftarrow{} X_n}{Pr}[\distin(1^n, x) = 1] - \underset{y \xleftarrow{} Y_n}{Pr}[\distin(1^n, y) = 1]\right| \leq \code{negl}(n)
$$
For example, pseudorandomness is just a special case of this, where one distribution ensemble is the output of a PRG and the other is actually a random distribution. Most of the definitions and assumptions we made so far is a special case or varient of computational indistinguishability.

\vspace{20px}
\textbf{Q4:} Why do we talk about "families"\footnote{KL Book 2nd ed. p. 244} of functions?

\textbf{A4:} It is because we are using just a ``member'' of that family during our experiments. We need many functions that show the properties defined by the family, such that we can randomly choose a function in there and use it.

Think of the first parameter as an index which chooses a function from that family. This is required so that an outsider does not know which function we are using.

\vspace{20px}
\textbf{Q5:} Formally define a one way function.

\textbf{A5:} A function $f$ is a one way function if:
\begin{enumerate}
	\item \textbf{(Easy to Compute)}: $\forall x$, there exists a polynomial time algorithm $M_f$ computing $f$, i.e. $M_f(x) = f(x)$
	\item \textbf{(Hard to Invert)}: $\forall \code{PPT}$ algorithms $\advrs$, it should be infeasible to calculate the inverse of $f$. Let $y=f(x)$. This is also shown as:
	$$
	\underset{x \xleftarrow{} \{0,1\}^n; y = f(x)}{Pr}[\advrs(1^n, y) \in f^{-1}(y)] \leq \code{negl}(n)
	$$ 
\end{enumerate}


\vspace{20px}
\textbf{Q6:} Formally define a one way permutation.

\textbf{A6:} A function $f$ is a one way permutation if $f$ is a one way length-preserving bijective function.

\vspace{20px}
\textbf{Q7:} Prove that if $f$ is a one-way function, then the function $g$ defined by $g(x_1, x_2) = (f(x_1), x_2)$ where $|x_1|=|x_2|$ is also a one-way function. Observe that $g$ reveals half of its input, but is nevertheless one-way.

\textbf{A7:} We had two conditions for a one-way function, \textbf{Easy-to-Compute} and \textbf{Hard-to-Invert}, immediately we can see that $g$ is \textbf{Easy-to-Compute}. So what we have to do is show for all PPT algorithms $\advrs$ there exists a negligible function \code{negl} s.t.
$$
Pr[\code{Invert}_{\advrs,g}(n)=1] \leq \code{negl}(n)
$$
Equivalently, 
$$
\underset{x_1 \xleftarrow{} \{0,1\}^n, x_2 \xleftarrow{} \{0,1\}^n}{Pr}[\advrs(1^n, g(x_1,x_2)) \in g^{-1}(g(x_1,x_2))] \leq \code{negl}(n)
$$
We can think of $g$ as a function that gives half of the input to $f$, and acts like an identity for the other half. Inverting identity function is easy, however inverting $f$ is infeasible, therefore inverting $g$ should be infeasible, thus $g$ is a one-way function.

\vspace{20px}
\textbf{Q8:} Prove that if $G$ is a pseudorandom generator with expansion factor $l(n)=n+1$ then $G'$ with the construction given below is a PRG with the expansion factor of $l'(n)=p(n)$ where $p(n)$ is polynomial in $n$.
On input $s \in \{0,1\}^n$, algorithm $G'$ does the following (see figure 6.1 in ED1 or figure 7.1 in ED2 of the textbook):
\begin{algorithm}
\caption{Algorithm of $G'$}
\label{alg:q8}
\begin{algorithmic}[1]
\STATE $\text{Set } t_0 := s$
\FOR{$i = 1, \ldots, p(n)$}
	\STATE{Let  $s_{i-1}$ be the first $n$ bits of  $t_{i-1}$, and let $\sigma_{i-1}$ denote the remaining $i-1$ bits. (When $i=1$, $s_0=t_0$ and $\sigma_0$ is the empty string.)}
	\STATE{Set $t_i := G(s_{i-1}) || \sigma_{i-1}$ }
\ENDFOR
\STATE{Output $t_{p(n)}$}
\end{algorithmic}
\end{algorithm}

\textbf{A8:} The proof will start by assuming that if there exists a PPT algorithm $\advrs$ that breaks $G'$, then we can construct an algorithm $\mathcal{B}$ that breaks $G$. We will define a game now.
\begin{algorithm}
\caption{\code{chal} at the beginning.}
\label{alg:q8proofc1}
\begin{algorithmic}[1]
\STATE{\code{Chal} chooses a bit $b \gets \{R, PR\}$}
\IF{b = R}
	\STATE{$r \gets \{0,1\}^{n+1}$}
\ELSE
	\STATE{$x \gets \{0,1\}^{n}$; $r \gets G(x)$}
\ENDIF
\STATE{\code{Chal} gives $1^n$ and $r$ to $\mathcal{B}$}
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Code of  $\mathcal{B}$}
\label{alg:q8proof}
\begin{algorithmic}[1]
\STATE{$\mathcal{B}$ takes $1^n$ and $r$ from \code{Chal}}
\STATE{$i \gets \{1, \ldots, p(n)\}$}
\STATE{$\sigma_{j-1} \gets \{0, 1\}^{j-1}$}
\STATE{$t_{j-1} := r || \sigma_{j-1}$}
\FOR{$i = j, \ldots, p(n)$}
	\STATE{Let  $s_{i-1}$ be the first $n$ bits of  $t_{i-1}$, and let $\sigma_{i-1}$ denote the remaining $i-1$ bits. (When $i=1$, $s_0=t_0$ and $\sigma_0$ is the empty string.)}
	\STATE{Set $t_i := G(s_{i-1}) || \sigma_{i-1}$ }
\ENDFOR
\STATE{$w = t_{p(n)}$}
\STATE{$\mathcal{B}$ gives $1^n$ and $t_{p(n)}$ to $\advrs$}
\STATE{$\advrs$ returns a response $b' \in \{R,PR\}$, which we then forward to \code{Chal}}
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{\code{chal} at the end.}
\label{alg:q8proofc2}
\begin{algorithmic}[1]
\IF{b = b'}
	\STATE{output 1}
\ELSE
	\STATE{output 0}
\ENDIF
\end{algorithmic}
\end{algorithm}

Define some hybrids as follows:
\begin{itemize}
	\item $H^i : s \gets \{0, 1\}^{n+i}$ and then continue from level $i$.
	\item $H^{first} = H^0 : s \gets \{0, 1\}^n; r\gets G'(s); r \in \{0, 1\}^{n+p(n)}$, this is like a PR experiment.
	\item $H^{last} = H^{p(n)} : s \gets \{0, 1\}^{p(n)}, r = s$, this is like a R experiment.
\end{itemize}

If $\advrs$ wins with $\epsilon(n)$ probability then $\mathcal{B}$ wins with at least $\epsilon(n)/p(n)$ probability, which means at least one neighbor of hybrids were distinguishable. However, we know that all neighbors are indistinguishable as the theorem states, therefore $\mathcal{B}$ wins only with negligible probability.
\end{document}